{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución de problemas con regresión Ridge\n",
    "\n",
    "En este tutorial conocerás cómo crear un modelo de regresión con la técnica de regularización con norma $L_2$, también llamada regresión Ridge. Para encontrar el mejor valor de su hiperparámetro, realizaremos un ajuste mediante la técnica de validación cruzada con k-Folds. En ese sentido, veremos cómo realizar los siguientes procesos:\n",
    "\n",
    "1. Importar las librerías necesarias.\n",
    "2. Cargar un conjunto de datos.\n",
    "3. Preparar los datos para el modelado.\n",
    "4. Entrenar un modelo de referencia usando regresión lineal.\n",
    "5. Realizar una búsqueda de hiperparámetros.\n",
    "\n",
    "Utilizaremos el conjunto de datos correspondiente a la caracterización de casas y su precio. Nuestro objetivo es, entonces, obtener un modelo para predecir el precio de una vivienda dadas sus características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías requeridas\n",
    "\n",
    "Importaremos la librería `pandas` y `scikit-learn`. En particular, usaremos las siguientes clases para entrenar el modelo de regresión Ridge:\n",
    "\n",
    "* `GridSearchCV`: clase para entrenar múltiples modelos variando sus parámetros. Se utiliza para hacer una búsqueda exhaustiva de los mejores valores para el entrenamiento de un modelo.\n",
    "* `KFold`: clase para definir múltiples conjuntos de entrenamiento y validación sobre el conjunto de datos.\n",
    "* `MinMaxScaler`, `RobustScaler` y `StandardScaler`: clases para escalar los valores de nuestro conjunto de datos.\n",
    "* `Ridge`: clase para crear y entrenar un modelo de regresión regularizada con norma $L_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(f\"Versión de Pandas: {version('pandas')}\")\n",
    "print(f\"Versión de Scikit-learn: {version('scikit-learn')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de datos\n",
    "\n",
    "Realizaremos la carga de datos usando la función de Pandas `read_csv()`, especificando la ruta y el separador del archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('data/kc_house_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos los primeros datos del conjunto usando `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparación de los datos\n",
    "\n",
    "Definiremos la variable `data` para almacenar un conjunto de datos modificado. En ese sentido, podremos tener una copia de los datos originales almacenada en la variable `data_raw`, por si en algún momento es necesario recuperar información que haya sido modificada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de variables poco relevantes\n",
    "\n",
    "Eliminaremos tres variables con poca relevancia para el precio de las viviendas: `id`, `date` y `zipcode`, haciendo uso de la función `drop()` sobre nuestro DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id','date','zipcode'], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos el resultado con `data.head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de datos\n",
    "\n",
    "Ahora dividiremos el conjunto de datos resultante en un conjunto de entrenamiento y uno de pruebas mediante la función `train_test_split()`. Usaremos el 80% de los datos para el entrenamiento y el 20% restante para las pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=9)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los algoritmos supervisados implementados en `scikit-learn` necesitan que las variables de entrada estén separadas de la variable objetivo, usaremos la función `drop` y definiremos `x_train` y `y_train`, que representan los valores de las variables independientes y los valores de la variable objetivo, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['price'],axis=\"columns\")\n",
    "y_train = train['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización\n",
    "\n",
    "Para el caso de regresión regularizada, la escala en la que se encuentran las variables se vuelve relevante, a diferencia de la regresión lineal simple. Específicamente, dado que los métodos de regularización actúan sobre la magnitud de los coeficientes del modelo, todos deben estar en la misma escala. En este caso utilizaremos un objeto de la clase `MinMaxScaler()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la variable `scaler` asignamos el objeto que corresponde al escalador para las variables numéricas, en Scikit-learn hay varios y los más comunes son los siguientes:\n",
    "\n",
    "* **StandardScaler**: Escala las variables para que la distribución de probabilidad de cada variable se comporte como una distribución normal (es decir, media 0 y varianza 1)\n",
    "* **MinMaxScaler**: Escala las variables en un rango especificado (que es [0,1] por defecto y puede definirse manualmente).\n",
    "* **RobustScaler**: Remueve la media y escala las variables usando el rango interquartil. Este es útil cuando las variables tienen valores atípicos (_outliers_)\n",
    "\n",
    "#### Experimento\n",
    "\n",
    "Intenta cambiar el escalador de la celda siguiente usando `StandardScaler()` o `RobustScaler()` y revisa qué efectos tiene cada uno en los coeficientes resultantes en la regresión y en el rendimiento del modelo. Diferentes escaladores tendrán mejores o peores resultados dependiendo de los datos.\n",
    "\n",
    "Si deseas ir más allá, puedes agregar el escalado de variables a la fase de búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = x_train.columns\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizaremos los nuevos valores del conjunto de entrenamiento usando `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de un modelo de referencia\n",
    "\n",
    "Con el conjunto de datos modificado, ahora entrenaremos un modelo de referencia, que nos permitirá ver cómo es el rendimiento de una regresión lineal simple con este conjunto de datos. Definiremos un objeto de tipo `LinearRegression()` y lo entrenaremos con la función `fit()`, utilizando el conjunto de entrenamiento separado en las variables independientes `x_train` y la variable objetivo `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_lineal = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos los coeficientes y el intercepto resultantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Coeficientes: ', reg_lineal.coef_)\n",
    "print ('Intercepto: ', reg_lineal.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Específicamente, cada variable tiene los siguientes coeficientes, que obtendremos usando `reg_lineal.coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(x_train.columns, reg_lineal.coef_),columns=[\"Variable\",\"Coeficiente\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Ahora utilizaremos el conjunto de pruebas para evaluar el desempeño del modelo. Separaremos las variables independientes y la variable objetivo, de la misma forma que para el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['price'],axis=\"columns\")\n",
    "y_test = test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También usaremos la variable `scaler` para escalar las variables independientes del conjunto de pruebas. Utilizaremos solamente la información del conjunto de entrenamiento, con el método `transform()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)\n",
    "x_test = pd.DataFrame(x_test, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, realizaremos las predicciones. Utilizaremos tres métricas para evaluar el desempeño del modelo de referencia: la raíz del error cuadrático medio, el error absoluto medio y el coeficiente de determinación: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = reg_lineal.predict(x_test)\n",
    "\n",
    "print('------ Modelo de regresión lineal simple----')\n",
    "print(\"RMSE: %.2f\" % root_mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: %.2f\" % mean_absolute_error(y_test, y_pred))\n",
    "print('R²: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, el modelo de regresión lineal simple se ajusta un 71% a los datos. En este caso, se tienen errores medios en el orden de los cientos de miles de dólares. Ahora veremos cómo se compara un modelo de regresión Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Búsqueda de hiperparámetros\n",
    "\n",
    "Cambiar el valor de los hiperparámetros tiene un impacto directo sobre el desempeño del modelo resultante, por lo que queremos encontrar un valor que resulte en el mejor desempeño posible. A continuación, ejecutaremos un procedimiento de búsqueda exhaustiva sobre el hiperparámetro `alpha` de la regresión Ridge, definiendo y entrenando múltiples modelos para, finalmente, elegir el valor del hiperparámetro que resulte en el modelo con el mejor desempeño.\n",
    "\n",
    "Primero crearemos un objeto de la clase `Ridge()`, que puede recibir como parámetro el valor de `alpha`. Este hiperparámetro corresponde a la constante que acompaña al término de penalización, es decir, `alpha` es usado para el control de la complejidad. En este caso no es necesario especificarlo, ya que cambiaremos su valor en cada iteración de la búsqueda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a definir un objeto de la clase `KFold()`, que toma el conjunto de entrenamiento original y lo separa en k grupos, usando uno como validación y el resto (k-1) como entrenamiento. En este caso, definiremos `k=10` y usaremos el parámetro `shuffle=True` para indicar que se cambie el orden de los datos antes de separarlos en los grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente utilizaremos un diccionario para definir nuestro espacio de búsqueda de hiperparámetros, es decir, los valores que vamos a probar y sobre los que decidiremos cuál escoger. Almacenaremos estos valores en la variable `param_grid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [1, 2, 5, 10, 15, 20, 100, 500]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a utilizar `GridSearchCV` para realizar la búsqueda exhaustiva del mejor hiperparámetro. Esta clase nos permitirá entrenar un modelo con todos los conjuntos obtenidos mediante el objeto `kfold`, además de todos los valores específicos para el hiperparámetro, seleccionando el mejor modelo entre todas las combinaciones posibles. En ese orden de ideas, definiremos el algoritmo `ridge`, los valores del hiperparámetro `param_grid`, y la estrategia de validación cruzada `kfold`: \n",
    "\n",
    "* La complejidad del modelo afecta el tiempo que tarda en entrenar, por lo que esta parte puede tardar más tiempo en completarse, puedes intentar agregar el parámetro `n_jobs=-1` para mejorar el rendimiento o usar `n_jobs=1` para limitarlo en caso de que el entorno falle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_grid = GridSearchCV(ridge, param_grid, cv=kfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, entrenaremos los modelos con los conjuntos definidos previamente:\n",
    "\n",
    "* la línea `%%time` permite ver cuánto tiempo tardó en ejecutarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "modelos_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendremos el mejor parámetro usando el atributo `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Mejor parámetro: {}\".format(modelos_grid.best_params_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el mejor valor del hiperparámetro `alpha` es 1. Posteriormente, almacenaremos el modelo ya entrenado usando el atributo `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_modelo = modelos_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, obtendremos los coeficientes del modelo de regresión regularizada utilizando el atributo `coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(x_train.columns, mejor_modelo.coef_),columns=[\"Variable\",\"Coeficiente\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las particularidades de la regresión Ridge es que, generalmente, los coeficientes resultantes tienen una magnitud menor a los coeficientes obtenidos con regresión lineal simple. Como puedes observar en nuestro mejor modelo, algunos de los coeficientes disminuyen. Debes tener en cuenta que la reducción de coeficientes es dependiente del valor del hiperparámetro `alpha`, por lo que en este caso la regularización no es tan fuerte y la reducción no es tan evidente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del mejor modelo\n",
    "\n",
    "A continuación realizaremos predicciones sobre el conjunto de pruebas para comparar con los valores de `y_test`. Utilizaremos la función `predict()` sobre el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mejor_modelo.predict(x_test)\n",
    "\n",
    "print('------ Modelo de regresión Ridge----')\n",
    "print(\"RMSE: %.2f\" % root_mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: %.2f\" % mean_absolute_error(y_test, y_pred))\n",
    "print('R²: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este conjunto de datos, el valor de R<sup>2</sup> se mantiene en 0.71 y, adicionalmente, el RMSE y el MAE mantienen valores similares al modelo de regresión lineal. Es decir, según las trés métricas, el rendimiento de generalización no es mejor con regularización. ¿El rendimiento podría mejorar si creas un modelo mezclando regresión polinomial con regularización?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cierre\n",
    "\n",
    "En este tutorial hemos utilizado nuevas clases de scikit-learn para entrenar modelos de regresión Ridge. Adicionalmente, observamos cómo escalar datos, definimos un objeto para realizar validación cruzada con k-Folds y realizamos una búsqueda exhaustiva de hiperparámetros. \n",
    "\n",
    "---\n",
    "Si quieres más información sobre regresión Ridge en `scikit_learn` puedes consultar el [sitio web oficial](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "Para la estandarización de datos con la clase `MinMaxScaler()` puedes consultar [este enlace](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "En particular, puedes ver el efecto que tiene cada escalador de Scikit-learn en [este ejemplo de scikit-learn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#)\n",
    "\n",
    "Para la búsqueda de hiperparámetros con la clase `GridSearchCV()` puedes consultar [este enlace](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "Finalmente, para obtener más información sobre la clase `KFold()` puedes ir [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "---\n",
    "*Creado por: Nicolás Díaz*\n",
    "\n",
    "*Última edición: Camilo Rozo*\n",
    "\n",
    "*Revisado por: Haydemar Nuñez*\n",
    "\n",
    "*Versión: Enero 2025*  \n",
    "\n",
    "*Universidad de los Andes*  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
